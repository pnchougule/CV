{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2. Training and Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "tfod"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnchougule/CV/blob/main/2_Training_and_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "source": [
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNBZEhvdClJx"
      },
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA1DIq5OpfDE"
      },
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180faa66-8f7b-4015-f5cc-8277534e779a"
      },
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.29.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: fastavro<2,>=0.21.4 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (56.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.1.95)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.13.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.5.2.52)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1650082 sha256=4fb2058ef108e7695aa48f42fcb87f727fad72d88325b9a541821675082aed6f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-crmbolpj/wheels/ac/8a/90/02d8042c0333b38a96341f55d93b379bb170f98b196de6b536\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKwqOun6ClJ1",
        "outputId": "2b99d50f-97c8-44fa-f596-4d1735545716"
      },
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-23 12:22:56.415588: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-05-23 12:22:58.195650: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-23 12:22:58.227386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-23 12:22:58.227993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-05-23 12:22:58.228082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-23 12:22:58.231207: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-23 12:22:58.231284: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-05-23 12:22:58.234103: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-05-23 12:22:58.234523: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-05-23 12:22:58.234621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2021-05-23 12:22:58.235263: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-05-23 12:22:58.235436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-05-23 12:22:58.235462: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-05-23 12:22:58.235800: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-05-23 12:22:58.235935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-23 12:22:58.235956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
            "W0523 12:22:58.444273 140517237122944 model_builder.py:1061] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.49s\n",
            "I0523 12:22:58.675676 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "I0523 12:22:59.177768 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "I0523 12:22:59.427700 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
            "I0523 12:22:59.649645 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0523 12:22:59.651763 140517237122944 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.68s\n",
            "I0523 12:23:01.332521 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0523 12:23:01.333431 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0523 12:23:01.352058 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0523 12:23:01.364893 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0523 12:23:01.383408 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
            "I0523 12:23:01.468679 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I0523 12:23:01.552399 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0523 12:23:01.642698 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
            "I0523 12:23:01.728142 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0523 12:23:01.814068 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "I0523 12:23:01.838457 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0523 12:23:01.995354 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0523 12:23:01.995515 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0523 12:23:01.995591 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0523 12:23:01.997503 140517237122944 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0523 12:23:02.011525 140517237122944 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0523 12:23:02.011644 140517237122944 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0523 12:23:02.059482 140517237122944 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0523 12:23:02.059607 140517237122944 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0523 12:23:02.186880 140517237122944 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0523 12:23:02.187055 140517237122944 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0523 12:23:02.315732 140517237122944 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0523 12:23:02.315889 140517237122944 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0523 12:23:02.638659 140517237122944 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0523 12:23:02.638828 140517237122944 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0523 12:23:02.839006 140517237122944 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0523 12:23:02.839189 140517237122944 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0523 12:23:03.133277 140517237122944 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0523 12:23:03.133449 140517237122944 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0523 12:23:03.208783 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0523 12:23:03.253920 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:03.300126 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0523 12:23:03.300268 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0523 12:23:03.300347 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0523 12:23:03.301807 140517237122944 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0523 12:23:03.315202 140517237122944 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0523 12:23:03.315308 140517237122944 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0523 12:23:03.422278 140517237122944 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0523 12:23:03.422413 140517237122944 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0523 12:23:03.606502 140517237122944 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0523 12:23:03.606659 140517237122944 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0523 12:23:03.795247 140517237122944 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0523 12:23:03.795409 140517237122944 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0523 12:23:04.052968 140517237122944 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0523 12:23:04.053164 140517237122944 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0523 12:23:04.327003 140517237122944 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0523 12:23:04.327194 140517237122944 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0523 12:23:04.705347 140517237122944 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0523 12:23:04.705524 140517237122944 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0523 12:23:04.881127 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0523 12:23:04.924010 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:04.980944 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0523 12:23:04.981114 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0523 12:23:04.981186 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0523 12:23:04.982645 140517237122944 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0523 12:23:04.996064 140517237122944 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0523 12:23:04.996194 140517237122944 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0523 12:23:05.096552 140517237122944 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0523 12:23:05.096698 140517237122944 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0523 12:23:05.414721 140517237122944 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0523 12:23:05.414893 140517237122944 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0523 12:23:05.613405 140517237122944 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0523 12:23:05.613574 140517237122944 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0523 12:23:05.881061 140517237122944 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0523 12:23:05.881236 140517237122944 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0523 12:23:06.153380 140517237122944 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0523 12:23:06.153554 140517237122944 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0523 12:23:06.542581 140517237122944 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0523 12:23:06.542763 140517237122944 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0523 12:23:06.720995 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0523 12:23:06.770344 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:06.833833 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0523 12:23:06.834000 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0523 12:23:06.834084 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0523 12:23:06.835831 140517237122944 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0523 12:23:06.849931 140517237122944 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0523 12:23:06.850054 140517237122944 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0523 12:23:06.950525 140517237122944 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0523 12:23:06.950671 140517237122944 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0523 12:23:07.143952 140517237122944 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0523 12:23:07.144167 140517237122944 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0523 12:23:07.338679 140517237122944 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0523 12:23:07.338845 140517237122944 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0523 12:23:07.673021 140517237122944 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0523 12:23:07.673218 140517237122944 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0523 12:23:08.021357 140517237122944 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0523 12:23:08.021538 140517237122944 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0523 12:23:08.510885 140517237122944 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0523 12:23:08.511074 140517237122944 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0523 12:23:08.856751 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0523 12:23:08.904508 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:08.964373 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0523 12:23:08.964540 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0523 12:23:08.964619 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0523 12:23:08.966114 140517237122944 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0523 12:23:08.978800 140517237122944 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0523 12:23:08.978917 140517237122944 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0523 12:23:09.080634 140517237122944 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0523 12:23:09.080784 140517237122944 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0523 12:23:09.341280 140517237122944 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0523 12:23:09.341454 140517237122944 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0523 12:23:09.609220 140517237122944 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0523 12:23:09.609400 140517237122944 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0523 12:23:10.022920 140517237122944 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0523 12:23:10.023116 140517237122944 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0523 12:23:10.457713 140517237122944 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0523 12:23:10.457889 140517237122944 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0523 12:23:11.167312 140517237122944 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0523 12:23:11.167499 140517237122944 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0523 12:23:11.388551 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0523 12:23:11.446325 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:11.522368 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0523 12:23:11.522525 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0523 12:23:11.522596 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0523 12:23:11.524069 140517237122944 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0523 12:23:11.536802 140517237122944 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0523 12:23:11.536911 140517237122944 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0523 12:23:11.697740 140517237122944 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0523 12:23:11.697906 140517237122944 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0523 12:23:12.025511 140517237122944 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0523 12:23:12.025690 140517237122944 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0523 12:23:12.530982 140517237122944 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0523 12:23:12.531176 140517237122944 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0523 12:23:13.010946 140517237122944 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0523 12:23:13.011157 140517237122944 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0523 12:23:13.554427 140517237122944 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0523 12:23:13.554606 140517237122944 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0523 12:23:14.370361 140517237122944 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0523 12:23:14.370547 140517237122944 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0523 12:23:14.774444 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0523 12:23:14.838278 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:14.918748 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0523 12:23:14.918935 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0523 12:23:14.919013 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0523 12:23:14.920528 140517237122944 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0523 12:23:14.933675 140517237122944 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0523 12:23:14.933786 140517237122944 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0523 12:23:15.098237 140517237122944 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0523 12:23:15.098399 140517237122944 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0523 12:23:15.491842 140517237122944 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0523 12:23:15.492029 140517237122944 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0523 12:23:15.885142 140517237122944 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0523 12:23:15.885313 140517237122944 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0523 12:23:16.445205 140517237122944 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0523 12:23:16.445380 140517237122944 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0523 12:23:17.229769 140517237122944 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0523 12:23:17.229959 140517237122944 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0523 12:23:18.331926 140517237122944 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0523 12:23:18.332117 140517237122944 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0523 12:23:18.794123 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0523 12:23:18.865659 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0523 12:23:18.954916 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0523 12:23:18.955115 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0523 12:23:18.955201 140517237122944 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0523 12:23:18.956997 140517237122944 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0523 12:23:18.969970 140517237122944 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0523 12:23:18.970103 140517237122944 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0523 12:23:19.174995 140517237122944 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0523 12:23:19.175196 140517237122944 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0523 12:23:19.639730 140517237122944 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0523 12:23:19.639905 140517237122944 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0523 12:23:20.105488 140517237122944 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0523 12:23:20.105672 140517237122944 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0523 12:23:20.826955 140517237122944 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0523 12:23:20.827152 140517237122944 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0523 12:23:21.824530 140517237122944 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0523 12:23:21.824712 140517237122944 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0523 12:23:23.238766 140517237122944 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0523 12:23:23.238958 140517237122944 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0523 12:23:23.949923 140517237122944 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0523 12:23:24.027798 140517237122944 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.3s\n",
            "I0523 12:23:24.136238 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.3s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0523 12:23:24.142417 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0523 12:23:24.144077 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0523 12:23:24.144546 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0523 12:23:24.145963 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0523 12:23:24.147340 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0523 12:23:24.147763 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0523 12:23:24.148714 140517237122944 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 25.959s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AnKOquAClJ2",
        "outputId": "eb993078-3c0e-4167-8917-f3f753123c11"
      },
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W4X85nb7ClJ3",
        "outputId": "ec713cd8-0175-490d-a85f-3ffda3b52433"
      },
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling protobuf-3.17.0:\n",
            "  Successfully uninstalled protobuf-3.17.0\n",
            "Uninstalling matplotlib-3.2.0:\n",
            "  Successfully uninstalled matplotlib-3.2.0\n",
            "Collecting protobuf\n",
            "  Using cached https://files.pythonhosted.org/packages/7e/16/7ba9dc81212c0e3865c08dcc9170259bc4e624fda783926fb84ed609ea25/protobuf-3.17.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n",
            "Collecting matplotlib==3.2\n",
            "  Using cached https://files.pythonhosted.org/packages/6c/ab/e1585a7101f8f7047376b59274ada50fefd637bd4cd99d2125a1b730845a/matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.19.5)\n",
            "\u001b[31mERROR: apache-beam 2.29.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.17.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDYOJcLvClJ3",
        "outputId": "77423d1d-e36c-4f00-e3a6-2d29018921f1"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMVYoHHfClJ3"
      },
      "source": [
        "import object_detection"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrwTE9nAClJ4",
        "outputId": "5982af1d-d13e-4209-85a3-d91f62936b78"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                       Version            \n",
            "----------------------------- -------------------\n",
            "absl-py                       0.12.0             \n",
            "alabaster                     0.7.12             \n",
            "albumentations                0.1.12             \n",
            "altair                        4.1.0              \n",
            "apache-beam                   2.29.0             \n",
            "appdirs                       1.4.4              \n",
            "argon2-cffi                   20.1.0             \n",
            "arviz                         0.11.2             \n",
            "astor                         0.8.1              \n",
            "astropy                       4.2.1              \n",
            "astunparse                    1.6.3              \n",
            "async-generator               1.10               \n",
            "atari-py                      0.2.6              \n",
            "atomicwrites                  1.4.0              \n",
            "attrs                         21.2.0             \n",
            "audioread                     2.1.9              \n",
            "autograd                      1.3                \n",
            "avro-python3                  1.10.2             \n",
            "Babel                         2.9.1              \n",
            "backcall                      0.2.0              \n",
            "beautifulsoup4                4.6.3              \n",
            "bleach                        3.3.0              \n",
            "blis                          0.4.1              \n",
            "bokeh                         2.3.2              \n",
            "Bottleneck                    1.3.2              \n",
            "branca                        0.4.2              \n",
            "bs4                           0.0.1              \n",
            "CacheControl                  0.12.6             \n",
            "cached-property               1.5.2              \n",
            "cachetools                    4.2.2              \n",
            "catalogue                     1.0.0              \n",
            "certifi                       2020.12.5          \n",
            "cffi                          1.14.5             \n",
            "cftime                        1.4.1              \n",
            "chainer                       7.4.0              \n",
            "chardet                       3.0.4              \n",
            "click                         8.0.0              \n",
            "cloudpickle                   1.3.0              \n",
            "cmake                         3.12.0             \n",
            "cmdstanpy                     0.9.5              \n",
            "colorcet                      2.0.6              \n",
            "colorlover                    0.3.0              \n",
            "community                     1.0.0b1            \n",
            "contextlib2                   0.5.5              \n",
            "convertdate                   2.3.2              \n",
            "coverage                      3.7.1              \n",
            "coveralls                     0.5                \n",
            "crcmod                        1.7                \n",
            "cufflinks                     0.17.3             \n",
            "cupy-cuda101                  7.4.0              \n",
            "cvxopt                        1.2.6              \n",
            "cvxpy                         1.0.31             \n",
            "cycler                        0.10.0             \n",
            "cymem                         2.0.5              \n",
            "Cython                        0.29.23            \n",
            "daft                          0.0.4              \n",
            "dask                          2.12.0             \n",
            "datascience                   0.10.6             \n",
            "debugpy                       1.0.0              \n",
            "decorator                     4.4.2              \n",
            "defusedxml                    0.7.1              \n",
            "descartes                     1.1.0              \n",
            "dill                          0.3.1.1            \n",
            "distributed                   1.25.3             \n",
            "dlib                          19.18.0            \n",
            "dm-tree                       0.1.6              \n",
            "docopt                        0.6.2              \n",
            "docutils                      0.17.1             \n",
            "dopamine-rl                   1.0.5              \n",
            "earthengine-api               0.1.264            \n",
            "easydict                      1.9                \n",
            "ecos                          2.0.7.post1        \n",
            "editdistance                  0.5.3              \n",
            "en-core-web-sm                2.2.5              \n",
            "entrypoints                   0.3                \n",
            "ephem                         3.7.7.1            \n",
            "et-xmlfile                    1.1.0              \n",
            "fa2                           0.3.5              \n",
            "fancyimpute                   0.4.3              \n",
            "fastai                        1.0.61             \n",
            "fastavro                      1.4.1              \n",
            "fastdtw                       0.3.4              \n",
            "fastprogress                  1.0.0              \n",
            "fastrlock                     0.6                \n",
            "fbprophet                     0.7.1              \n",
            "feather-format                0.4.1              \n",
            "filelock                      3.0.12             \n",
            "firebase-admin                4.4.0              \n",
            "fix-yahoo-finance             0.0.22             \n",
            "Flask                         1.1.2              \n",
            "flatbuffers                   1.12               \n",
            "folium                        0.8.3              \n",
            "future                        0.18.2             \n",
            "gast                          0.4.0              \n",
            "GDAL                          2.2.2              \n",
            "gdown                         3.6.4              \n",
            "gensim                        3.6.0              \n",
            "geographiclib                 1.50               \n",
            "geopy                         1.17.0             \n",
            "gin-config                    0.4.0              \n",
            "glob2                         0.7                \n",
            "google                        2.0.3              \n",
            "google-api-core               1.26.3             \n",
            "google-api-python-client      1.12.8             \n",
            "google-auth                   1.30.0             \n",
            "google-auth-httplib2          0.0.4              \n",
            "google-auth-oauthlib          0.4.4              \n",
            "google-cloud-bigquery         1.21.0             \n",
            "google-cloud-bigquery-storage 1.1.0              \n",
            "google-cloud-core             1.0.3              \n",
            "google-cloud-datastore        1.8.0              \n",
            "google-cloud-firestore        1.7.0              \n",
            "google-cloud-language         1.2.0              \n",
            "google-cloud-storage          1.18.1             \n",
            "google-cloud-translate        1.5.0              \n",
            "google-colab                  1.0.0              \n",
            "google-pasta                  0.2.0              \n",
            "google-resumable-media        0.4.1              \n",
            "googleapis-common-protos      1.53.0             \n",
            "googledrivedownloader         0.4                \n",
            "graphviz                      0.10.1             \n",
            "greenlet                      1.1.0              \n",
            "grpcio                        1.34.1             \n",
            "gspread                       3.0.1              \n",
            "gspread-dataframe             3.0.8              \n",
            "gym                           0.17.3             \n",
            "h5py                          3.1.0              \n",
            "hdfs                          2.6.0              \n",
            "HeapDict                      1.0.1              \n",
            "hijri-converter               2.1.1              \n",
            "holidays                      0.10.5.2           \n",
            "holoviews                     1.14.3             \n",
            "html5lib                      1.0.1              \n",
            "httpimport                    0.5.18             \n",
            "httplib2                      0.17.4             \n",
            "httplib2shim                  0.0.3              \n",
            "humanize                      0.5.1              \n",
            "hyperopt                      0.1.2              \n",
            "ideep4py                      2.0.0.post3        \n",
            "idna                          2.10               \n",
            "imageio                       2.4.1              \n",
            "imagesize                     1.2.0              \n",
            "imbalanced-learn              0.4.3              \n",
            "imblearn                      0.0                \n",
            "imgaug                        0.2.9              \n",
            "importlib-metadata            4.0.1              \n",
            "importlib-resources           5.1.2              \n",
            "imutils                       0.5.4              \n",
            "inflect                       2.1.0              \n",
            "iniconfig                     1.1.1              \n",
            "intel-openmp                  2021.2.0           \n",
            "intervaltree                  2.1.0              \n",
            "ipykernel                     4.10.1             \n",
            "ipython                       5.5.0              \n",
            "ipython-genutils              0.2.0              \n",
            "ipython-sql                   0.3.9              \n",
            "ipywidgets                    7.6.3              \n",
            "itsdangerous                  2.0.0              \n",
            "jax                           0.2.13             \n",
            "jaxlib                        0.1.66+cuda110     \n",
            "jdcal                         1.4.1              \n",
            "jedi                          0.18.0             \n",
            "jieba                         0.42.1             \n",
            "Jinja2                        2.11.3             \n",
            "joblib                        1.0.1              \n",
            "jpeg4py                       0.1.4              \n",
            "jsonschema                    2.6.0              \n",
            "jupyter                       1.0.0              \n",
            "jupyter-client                5.3.5              \n",
            "jupyter-console               5.2.0              \n",
            "jupyter-core                  4.7.1              \n",
            "jupyterlab-pygments           0.1.2              \n",
            "jupyterlab-widgets            1.0.0              \n",
            "kaggle                        1.5.12             \n",
            "kapre                         0.1.3.1            \n",
            "Keras                         2.4.3              \n",
            "keras-nightly                 2.5.0.dev2021032900\n",
            "Keras-Preprocessing           1.1.2              \n",
            "keras-vis                     0.4.1              \n",
            "kiwisolver                    1.3.1              \n",
            "knnimpute                     0.1.0              \n",
            "korean-lunar-calendar         0.2.1              \n",
            "librosa                       0.8.0              \n",
            "lightgbm                      2.2.3              \n",
            "llvmlite                      0.34.0             \n",
            "lmdb                          0.99               \n",
            "LunarCalendar                 0.0.9              \n",
            "lvis                          0.5.3              \n",
            "lxml                          4.2.6              \n",
            "Markdown                      3.3.4              \n",
            "MarkupSafe                    2.0.0              \n",
            "matplotlib                    3.2.0              \n",
            "matplotlib-inline             0.1.2              \n",
            "matplotlib-venn               0.11.6             \n",
            "missingno                     0.4.2              \n",
            "mistune                       0.8.4              \n",
            "mizani                        0.6.0              \n",
            "mkl                           2019.0             \n",
            "mlxtend                       0.14.0             \n",
            "more-itertools                8.7.0              \n",
            "moviepy                       0.2.3.5            \n",
            "mpmath                        1.2.1              \n",
            "msgpack                       1.0.2              \n",
            "multiprocess                  0.70.11.1          \n",
            "multitasking                  0.0.9              \n",
            "murmurhash                    1.0.5              \n",
            "music21                       5.5.0              \n",
            "natsort                       5.5.0              \n",
            "nbclient                      0.5.3              \n",
            "nbconvert                     5.6.1              \n",
            "nbformat                      5.1.3              \n",
            "nest-asyncio                  1.5.1              \n",
            "netCDF4                       1.5.6              \n",
            "networkx                      2.5.1              \n",
            "nibabel                       3.0.2              \n",
            "nltk                          3.2.5              \n",
            "notebook                      5.3.1              \n",
            "np-utils                      0.5.12.1           \n",
            "numba                         0.51.2             \n",
            "numexpr                       2.7.3              \n",
            "numpy                         1.19.5             \n",
            "nvidia-ml-py3                 7.352.0            \n",
            "oauth2client                  4.1.3              \n",
            "oauthlib                      3.1.0              \n",
            "object-detection              0.1                \n",
            "okgrade                       0.4.3              \n",
            "opencv-contrib-python         4.1.2.30           \n",
            "opencv-python                 4.1.2.30           \n",
            "opencv-python-headless        4.5.2.52           \n",
            "openpyxl                      2.5.9              \n",
            "opt-einsum                    3.3.0              \n",
            "osqp                          0.6.2.post0        \n",
            "packaging                     20.9               \n",
            "palettable                    3.3.0              \n",
            "pandas                        1.1.5              \n",
            "pandas-datareader             0.9.0              \n",
            "pandas-gbq                    0.13.3             \n",
            "pandas-profiling              1.4.1              \n",
            "pandocfilters                 1.4.3              \n",
            "panel                         0.11.3             \n",
            "param                         1.10.1             \n",
            "parso                         0.8.2              \n",
            "pathlib                       1.0.1              \n",
            "patsy                         0.5.1              \n",
            "pexpect                       4.8.0              \n",
            "pickleshare                   0.7.5              \n",
            "Pillow                        7.1.2              \n",
            "pip                           19.3.1             \n",
            "pip-tools                     4.5.1              \n",
            "plac                          1.1.3              \n",
            "plotly                        4.4.1              \n",
            "plotnine                      0.6.0              \n",
            "pluggy                        0.7.1              \n",
            "pooch                         1.3.0              \n",
            "portalocker                   2.0.0              \n",
            "portpicker                    1.3.9              \n",
            "prefetch-generator            1.0.1              \n",
            "preshed                       3.0.5              \n",
            "prettytable                   2.1.0              \n",
            "progressbar2                  3.38.0             \n",
            "prometheus-client             0.10.1             \n",
            "promise                       2.3                \n",
            "prompt-toolkit                1.0.18             \n",
            "protobuf                      3.17.0             \n",
            "psutil                        5.4.8              \n",
            "psycopg2                      2.7.6.1            \n",
            "ptyprocess                    0.7.0              \n",
            "py                            1.10.0             \n",
            "py-cpuinfo                    8.0.0              \n",
            "pyarrow                       3.0.0              \n",
            "pyasn1                        0.4.8              \n",
            "pyasn1-modules                0.2.8              \n",
            "pycocotools                   2.0.2              \n",
            "pycparser                     2.20               \n",
            "pyct                          0.4.8              \n",
            "pydata-google-auth            1.2.0              \n",
            "pydot                         1.3.0              \n",
            "pydot-ng                      2.0.0              \n",
            "pydotplus                     2.0.2              \n",
            "PyDrive                       1.3.1              \n",
            "pyemd                         0.5.1              \n",
            "pyerfa                        1.7.3              \n",
            "pyglet                        1.5.0              \n",
            "Pygments                      2.6.1              \n",
            "pygobject                     3.26.1             \n",
            "pymc3                         3.11.2             \n",
            "PyMeeus                       0.5.11             \n",
            "pymongo                       3.11.4             \n",
            "pymystem3                     0.2.0              \n",
            "PyOpenGL                      3.1.5              \n",
            "pyparsing                     2.4.7              \n",
            "pyrsistent                    0.17.3             \n",
            "pysndfile                     1.3.8              \n",
            "PySocks                       1.7.1              \n",
            "pystan                        2.19.1.1           \n",
            "pytest                        3.6.4              \n",
            "python-apt                    0.0.0              \n",
            "python-chess                  0.23.11            \n",
            "python-dateutil               2.8.1              \n",
            "python-louvain                0.15               \n",
            "python-slugify                5.0.2              \n",
            "python-utils                  2.5.6              \n",
            "pytz                          2018.9             \n",
            "pyviz-comms                   2.0.1              \n",
            "PyWavelets                    1.1.1              \n",
            "PyYAML                        5.4.1              \n",
            "pyzmq                         22.0.3             \n",
            "qdldl                         0.1.5.post0        \n",
            "qtconsole                     5.1.0              \n",
            "QtPy                          1.9.0              \n",
            "regex                         2019.12.20         \n",
            "requests                      2.25.1             \n",
            "requests-oauthlib             1.3.0              \n",
            "resampy                       0.2.2              \n",
            "retrying                      1.3.3              \n",
            "rpy2                          3.4.4              \n",
            "rsa                           4.7.2              \n",
            "sacrebleu                     1.5.1              \n",
            "scikit-image                  0.16.2             \n",
            "scikit-learn                  0.22.2.post1       \n",
            "scipy                         1.4.1              \n",
            "screen-resolution-extra       0.0.0              \n",
            "scs                           2.1.3              \n",
            "seaborn                       0.11.1             \n",
            "semver                        2.13.0             \n",
            "Send2Trash                    1.5.0              \n",
            "sentencepiece                 0.1.95             \n",
            "seqeval                       1.2.2              \n",
            "setuptools                    56.1.0             \n",
            "setuptools-git                1.2                \n",
            "Shapely                       1.7.1              \n",
            "simplegeneric                 0.8.1              \n",
            "six                           1.15.0             \n",
            "sklearn                       0.0                \n",
            "sklearn-pandas                1.8.0              \n",
            "smart-open                    5.0.0              \n",
            "snowballstemmer               2.1.0              \n",
            "sortedcontainers              2.3.0              \n",
            "SoundFile                     0.10.3.post1       \n",
            "spacy                         2.2.4              \n",
            "Sphinx                        1.8.5              \n",
            "sphinxcontrib-serializinghtml 1.1.4              \n",
            "sphinxcontrib-websupport      1.2.4              \n",
            "SQLAlchemy                    1.4.15             \n",
            "sqlparse                      0.4.1              \n",
            "srsly                         1.0.5              \n",
            "statsmodels                   0.10.2             \n",
            "sympy                         1.7.1              \n",
            "tables                        3.4.4              \n",
            "tabulate                      0.8.9              \n",
            "tblib                         1.7.0              \n",
            "tensorboard                   2.5.0              \n",
            "tensorboard-data-server       0.6.1              \n",
            "tensorboard-plugin-wit        1.8.0              \n",
            "tensorflow                    2.5.0              \n",
            "tensorflow-addons             0.13.0             \n",
            "tensorflow-datasets           4.0.1              \n",
            "tensorflow-estimator          2.5.0              \n",
            "tensorflow-gcs-config         2.4.0              \n",
            "tensorflow-hub                0.12.0             \n",
            "tensorflow-metadata           0.30.0             \n",
            "tensorflow-model-optimization 0.5.0              \n",
            "tensorflow-probability        0.12.1             \n",
            "termcolor                     1.1.0              \n",
            "terminado                     0.9.5              \n",
            "testpath                      0.4.4              \n",
            "text-unidecode                1.3                \n",
            "textblob                      0.15.3             \n",
            "textgenrnn                    1.4.1              \n",
            "tf-models-official            2.5.0              \n",
            "tf-slim                       1.1.0              \n",
            "Theano-PyMC                   1.1.2              \n",
            "thinc                         7.4.0              \n",
            "tifffile                      2021.4.8           \n",
            "toml                          0.10.2             \n",
            "toolz                         0.11.1             \n",
            "torch                         1.8.1+cu101        \n",
            "torchsummary                  1.5.1              \n",
            "torchtext                     0.9.1              \n",
            "torchvision                   0.9.1+cu101        \n",
            "tornado                       5.1.1              \n",
            "tqdm                          4.41.1             \n",
            "traitlets                     5.0.5              \n",
            "tweepy                        3.10.0             \n",
            "typeguard                     2.7.1              \n",
            "typing-extensions             3.7.4.3            \n",
            "tzlocal                       1.5.1              \n",
            "uritemplate                   3.0.1              \n",
            "urllib3                       1.24.3             \n",
            "vega-datasets                 0.9.0              \n",
            "wasabi                        0.8.2              \n",
            "wcwidth                       0.2.5              \n",
            "webencodings                  0.5.1              \n",
            "Werkzeug                      2.0.0              \n",
            "wheel                         0.36.2             \n",
            "widgetsnbextension            3.5.1              \n",
            "wordcloud                     1.5.0              \n",
            "wrapt                         1.12.1             \n",
            "xarray                        0.18.0             \n",
            "xgboost                       0.90               \n",
            "xkit                          0.0.0              \n",
            "xlrd                          1.1.0              \n",
            "xlwt                          1.3.0              \n",
            "yellowbrick                   0.9.1              \n",
            "zict                          2.0.0              \n",
            "zipp                          3.4.1              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "ef69c442-b927-495b-e1f4-25e79e5982c3"
      },
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-23 12:24:11--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.15.80, 2607:f8b0:4004:810::2010\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.15.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-23 12:24:12 (164 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "source": [
        "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'ThankYou', 'id':3}, {'name':'hello', 'id':4}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "source": [
        "\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWpb_BVUpfDD"
      },
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13rQdZO-ClJ8"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "caae8845-3953-435f-d3fb-372ac97d08c8"
      },
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "d52ef97c-f862-457a-d2b3-1650293889b4"
      },
      "source": [
        "config"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "297d4988-73a6-4e60-95f7-5040d8ea34f0"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "e971b601-7c1e-4666-dfe9-9605949a9e42"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-23 11:33:25.627118: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-23 11:33:27.642568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-23 11:33:27.670454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-23 11:33:27.671072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-05-23 11:33:27.671116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-23 11:33:27.673948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-23 11:33:27.674041: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-05-23 11:33:27.675861: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-05-23 11:33:27.676217: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-05-23 11:33:27.676316: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2021-05-23 11:33:27.676998: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-05-23 11:33:27.677191: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-05-23 11:33:27.677219: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-05-23 11:33:27.677609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-05-23 11:33:27.677747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-23 11:33:27.677765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0523 11:33:27.678344 139879688415104 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "W0523 11:33:27.678601 139879688415104 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0523 11:33:27.680675 139879688415104 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0523 11:33:27.684361 139879688415104 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0523 11:33:27.684514 139879688415104 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0523 11:33:27.703585 139879688415104 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0523 11:33:27.707208 139879688415104 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0523 11:33:27.707363 139879688415104 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0523 11:33:27.707445 139879688415104 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0523 11:33:27.707524 139879688415104 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0523 11:33:27.710387 139879688415104 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0523 11:33:27.729353 139879688415104 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0523 11:33:34.145442 139879688415104 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0523 11:33:36.935107 139879688415104 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0523 11:33:38.527333 139879688415104 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-05-23 11:33:40.551142: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-05-23 11:33:40.556560: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "6b31c0f9-3107-4250-af09-ce90469332a9"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTV2jGBpfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a3e0d4-3659-43c3-c008-5ce928fc07ff"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-23 09:16:41.865342: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0523 09:16:43.877016 139886777001856 model_lib_v2.py:1064] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0523 09:16:43.877306 139886777001856 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0523 09:16:43.877448 139886777001856 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0523 09:16:43.877550 139886777001856 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0523 09:16:43.877682 139886777001856 model_lib_v2.py:1085] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2021-05-23 09:16:43.881964: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-23 09:16:43.888979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-23 09:16:43.889541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-05-23 09:16:43.889575: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-23 09:16:43.892497: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-23 09:16:43.892569: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-05-23 09:16:43.894543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-05-23 09:16:43.894964: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-05-23 09:16:43.895062: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2021-05-23 09:16:43.895737: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-05-23 09:16:43.895927: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-05-23 09:16:43.895952: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-05-23 09:16:43.896254: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-05-23 09:16:43.896383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-23 09:16:43.896405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0523 09:16:43.917630 139886777001856 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0523 09:16:43.917854 139886777001856 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0523 09:16:43.917946 139886777001856 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0523 09:16:43.918023 139886777001856 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0523 09:16:43.919290 139886777001856 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0523 09:16:43.936788 139886777001856 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0523 09:16:47.479027 139886777001856 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0523 09:16:48.535119 139886777001856 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "I0523 09:16:50.978721 139886777001856 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
            "I0523 10:16:50.581967 139886777001856 checkpoint_utils.py:203] Timed-out waiting for a checkpoint.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYk4_oIpfDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "6a975803-c6ad-4a27-de02-c95c7bab3bae"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-47dd4b277c51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMakeNdarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmake_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mget_static_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tf_type\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_tensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypeSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_tf_type' from 'tensorflow.python.framework.tensor_util' (/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDnQg-cYpfDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "396b1128-b91b-4618-ac1c-8a7b011c2dd3"
      },
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/my_ssd_mobnet/ckpt-5",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2262\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2264\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2150\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mInitializationOnlyStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m     \u001b[0mgraph_building\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/my_ssd_mobnet/ckpt-5",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c8a430a57496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Restore checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHECKPOINT_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ckpt-5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2266\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m           \u001b[0;34m\"Could not find checkpoint or SavedModel at {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m           .format(orig_save_path))\n\u001b[0m\u001b[1;32m   2269\u001b[0m     \u001b[0;31m# Create the save counter now so it gets initialized with other variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m     \u001b[0;31m# when graph building. Creating it earlier would lead to errors when using,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find checkpoint or SavedModel at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-5."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpzn1SMry1yK"
      },
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# 10. Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Piu9x0ClKH"
      },
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zG2eq0pClKO"
      },
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whShhB0x3PYJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}